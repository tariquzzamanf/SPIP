{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Description\n","We pass each video to LLMs to generate textual descritions, no descrition format is given"],"metadata":{"id":"WPayWLrI2iTq"}},{"cell_type":"code","source":["video_file_path = '/content/drive/MyDrive/research/BDSLW60GPT/Dataset/u4u8r/aam/U4W37F_trial_3_R.mp4'\n"],"metadata":{"id":"CwutmR-btcLz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Single File Test"],"metadata":{"id":"qttu5a8dChVK"}},{"cell_type":"code","metadata":{"id":"pMh_3zYk45z5","executionInfo":{"status":"ok","timestamp":1753718028492,"user_tz":-360,"elapsed":22452,"user":{"displayName":"Tariq Zaman","userId":"06097184597384541396"}},"colab":{"base_uri":"https://localhost:8080/","height":176},"outputId":"373dd617-6ad4-44f9-dc46-7221c29bec32"},"source":["import google.generativeai as genai\n","from google.colab import drive, userdata\n","import time\n","\n","# Make sure to add your GOOGLE_API_KEY to the Colab Secrets Manager\n","try:\n","    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n","    genai.configure(api_key=GOOGLE_API_KEY)\n","except userdata.SecretNotFoundError as e:\n","    print('Secret not found. Please add your GOOGLE_API_KEY to the Colab Secrets Manager.')\n","    # You can also add the key directly like this:\n","    # genai.configure(api_key=\"YOUR_GOOGLE_API_KEY\")\n","\n","\n","# === Step 1: Mount Google Drive ===\n","drive.mount('/content/drive')\n","# This is the path to the video file we just downloaded\n","video_file_path = '/content/drive/MyDrive/research/BDSLW60GPT/Dataset/u4u8r/aam/U4W37F_trial_3_R.mp4'\n","\n","def generate_description(video_path, prompt):\n","  \"\"\"\n","  This function takes a video file path and a prompt as input,\n","  uploads the video, and returns a description generated by an LLM.\n","  \"\"\"\n","  model = genai.GenerativeModel('gemini-2.5-pro')\n","\n","  print(f\"Uploading file...\")\n","  video_file = genai.upload_file(path=video_path)\n","  print(f\"Completed upload: {video_file.uri}\")\n","\n","  # Wait for the video to be processed.\n","  while video_file.state.name == \"PROCESSING\":\n","      print('Waiting for video to be processed...')\n","      time.sleep(10)\n","      video_file = genai.get_file(video_file.name)\n","\n","  if video_file.state.name == \"FAILED\":\n","    raise ValueError(video_file.state.name)\n","\n","  # Generate content with the video and prompt\n","  response = model.generate_content([prompt, video_file])\n","\n","  return response.text\n","\n","# The prompt from the previous cell\n","prompt = \"\"\"\n","You are an expert sign language motion analyst.\n","You will be given a video of a single hand sign gesture.\n","Your task is to generate a precise, natural language, movement-focused description of the gesture.\n","\n","Guidelines:\n","1. Break the description into ordered steps (Step 1, Step 2, etc.) that together capture the full gesture.\n","2. Describe what each hand is doing (right hand, left hand, or both), and specify finger involvement when clearly distinguishable.\n","3. Integrate the following movement parameters naturally into your step-by-step narrative:\n","   - Handshape (e.g., open, fist, hooked, pointing)\n","   - Type and direction of movement (e.g., straight upward, circular outward, twisting inward)\n","   - Palm orientation (e.g., facing forward, downward)\n","   - Relative body location (e.g., near the forehead, at chest level, beside the shoulder)\n","   - Spatial interaction between hands (e.g., touching, parallel, crossing)\n","   - Temporal dynamics (e.g., smooth transition, repeated motion, paused hold)\n","   - Non-manual cues (e.g., neutral face, raised eyebrows, head tilt)\n","   - Lexical context (starting position, transition phase, holding position, ending)\n","\n","4. Avoid listing these categories explicitly. Instead, embed them fluidly into your language so the description reads like a natural narrative of observed motion.\n","5. Do NOT include the meaning of the sign. Focus only on physical and expressive detail.\n","6. Keep the tone clear, concise, and easy to follow. Do not use technical or linguistic jargon.\n","7. Output only the step-by-step description. Do not include any introductory or closing remarks.\n","\"\"\"\n","\n","description = generate_description(video_file_path, prompt)\n","print(description)"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Uploading file...\n","Completed upload: https://generativelanguage.googleapis.com/v1beta/files/rd60lg161fua\n","Step 1: The right hand starts as a fist, held with the palm facing inward towards the right cheek, and the thumb side oriented upwards.\n","\n","Step 2: In a single, short motion, the hand moves forward and slightly downward, away from the face. As it moves, the fingers uncurl and extend forward from the fist.\n","\n","Step 3: The gesture ends with the hand paused a few inches in front of the mouth. The fingers are now loosely together and slightly curled, pointing forward, with the palm still facing inward. The facial expression is neutral throughout the movement.\n"]}]},{"cell_type":"markdown","source":["## Prompts"],"metadata":{"id":"Td5sNqnAxD6R"}},{"cell_type":"markdown","source":["### Basic, no structure, no hand mentioned\n","prompt = \"\"\"\n","You are an expert sign language motion analyst.\n","You will be given a video of a single hand sign gesture.\n","Your job is to produce a clear, accurate, and sequential description of the gesture, focusing on movement and meaning.\n","\n","Guidelines:\n","1. Describe the gesture in steps, following the order of motion (e.g., \"Step 1: Hand rises near the chest. Step 2: Fingers spread outward while rotating clockwise\").\n","2. Focus on the overall movement, direction, hand shape changes, and important transitions.\n","3. Avoid guessing the meaning or label. Only describe what is physically happening.\n","4. Be specific but concise. Use natural language rather than technical jargon.\n","5. Capture the \"flow\" of the gesture so another system can infer the meaning later.\n","6. Output only the description (no introductions or conclusions).\n","\"\"\""],"metadata":{"id":"YM1dG5n9xFlc"}},{"cell_type":"markdown","source":["### VideoToUnstructuredText_sign_descriptions_With_LR_hand_info\n","prompt = \"\"\"\n","You are an expert sign language motion analyst.\n","You will be given a video of a single hand sign gesture.\n","Your task is to generate a precise, sequential, and movement-focused description of the gesture.\n","\n","Guidelines:\n","1. Break the description into ordered steps (Step 1, Step 2, etc.) capturing the full motion sequence.\n","2. Always specify which hand is involved (right hand, left hand, or both) and describe their actions separately if needed, similarly mention the fingers if there is a very clear distinction among them.\n","3. Focus on:\n","   - Hand positions relative to the body (chest, head, side, etc.).\n","   - Handshape changes (fist, fingers spread, pointing, etc.).\n","   - Motion direction (up, down, circular, inward, outward).\n","   - Wrist rotations or pauses.\n","4. Capture the full flow of the gesture so the sequence can be understood clearly.\n","5. Do NOT provide the sign's meaning or label. Only describe the physical movements.\n","6. Use clear, natural language. Avoid technical or linguistic jargon.\n","7. Output only the step-by-step description, no additional text.\n","\"\"\""],"metadata":{"id":"8K4W_5YkxMGl"}},{"cell_type":"markdown","source":["# Structured Discrete Values\n","prompt = \"\"\"\n","You are an expert sign language motion analyst.\n","You will be given a video of a single hand sign gesture.\n","Your task is to break the gesture into steps and extract only structured, discrete feature values for each step.\n","No natural-language sentences — only standardized attributes.\n","\n","Guidelines:\n","1. Divide the gesture into ordered steps (Step 1, Step 2, etc.) capturing every motion change.\n","2. For each step, generate a JSON-like feature set with the following keys:\n","   - Handshape: (open, fist, hooked, pointing, spread, bent, extended, etc.)\n","   - MovementType: (static, circular, straight, twisting, grabbing, rotating, spreading, pulling, squeezing)\n","   - Location: (relative to body — head, forehead, ear, eye, nose, mouth, face, neck, shoulder, chest, waist, side)\n","   - PalmOrientation: (forward, inward, outward, upward, downward)\n","   - SpatialInteraction: (touching, crossing, parallel, apart, overlapping)\n","   - MovementDirection: (inward, outward, left, right, upward, downward, forward, backward, straight)\n","   - TemporalDynamics: (smooth, abrupt, repeated, paused, continuous)\n","   - NonManualCues: (neutral, nodding, raised eyebrows, head tilt, facial tension)\n","   - LexicalContext: (starting position, motion, transition, holding, ending)\n","\n","3. Always specify which hand is involved (right hand, left hand, or both) within the feature values when relevant (e.g., `\"Handshape\": \"right-hand spread, left-hand fist\"`).\n","\n","4. Do NOT provide natural-language sentences or the sign meaning.\n","\n","5. Output format: For each step, write only:\n","```\n","\n","Step N:\n","{\n","\"Handshape\": \"...\",\n","\"MovementType\": \"...\",\n","\"Location\": \"...\",\n","\"PalmOrientation\": \"...\",\n","\"SpatialInteraction\": \"...\",\n","\"MovementDirection\": \"...\",\n","\"TemporalDynamics\": \"...\",\n","\"NonManualCues\": \"...\",\n","\"LexicalContext\": \"...\"\n","}\n","\n","```\n","6. Output only the ordered steps for the gesture. No introductions or summaries.\"\"\"\n"],"metadata":{"id":"wIjbj5puycSl"}},{"cell_type":"markdown","source":["### Parameter Injection Natural Language\n","prompt = \"\"\"\n","You are an expert sign language motion analyst.\n","You will be given a video of a single hand sign gesture.\n","Your task is to generate a precise, natural language, movement-focused description of the gesture.\n","\n","Guidelines:\n","1. Break the description into ordered steps (Step 1, Step 2, etc.) that together capture the full gesture.\n","2. Describe what each hand is doing (right hand, left hand, or both), and specify finger involvement when clearly distinguishable.\n","3. Integrate the following movement parameters naturally into your step-by-step narrative:\n","   - Handshape (e.g., open, fist, hooked, pointing)\n","   - Type and direction of movement (e.g., straight upward, circular outward, twisting inward)\n","   - Palm orientation (e.g., facing forward, downward)\n","   - Relative body location (e.g., near the forehead, at chest level, beside the shoulder)\n","   - Spatial interaction between hands (e.g., touching, parallel, crossing)\n","   - Temporal dynamics (e.g., smooth transition, repeated motion, paused hold)\n","   - Non-manual cues (e.g., neutral face, raised eyebrows, head tilt)\n","   - Lexical context (starting position, transition phase, holding position, ending)\n","\n","4. Avoid listing these categories explicitly. Instead, embed them fluidly into your language so the description reads like a natural narrative of observed motion.\n","5. Do NOT include the meaning of the sign. Focus only on physical and expressive detail.\n","6. Keep the tone clear, concise, and easy to follow. Do not use technical or linguistic jargon.\n","7. Output only the step-by-step description. Do not include any introductory or closing remarks.\n","\"\"\""],"metadata":{"id":"GFtbVoCC8mdi"}},{"cell_type":"markdown","source":["### Batch Test"],"metadata":{"id":"YFaLHMDHCj3C"}},{"cell_type":"code","source":["import os\n","import csv\n","import time\n","import google.generativeai as genai\n","from google.colab import drive, userdata\n","from IPython.display import clear_output\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Configure API Key\n","try:\n","    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n","    genai.configure(api_key=GOOGLE_API_KEY)\n","except userdata.SecretNotFoundError:\n","    print('Secret not found. Please add your GOOGLE_API_KEY to the Colab Secrets Manager.')\n","    # Or set manually:\n","    # genai.configure(api_key=\"YOUR_GOOGLE_API_KEY\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WHWbz4UdCk0m","executionInfo":{"status":"ok","timestamp":1753719660153,"user_tz":-360,"elapsed":5604,"user":{"displayName":"Tariq Zaman","userId":"06097184597384541396"}},"outputId":"633e6ae0-b6f5-47c9-db24-cc1c9cbfabfc"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# Path to your dataset directory (change this)\n","base_directory = '/content/drive/MyDrive/research/BDSLW60GPT/Dataset/u4u8r'\n","\n","# CSV output file\n","output_csv = '/content/drive/MyDrive/research/BDSLW60GPT/Output/VideoToUnstructuredText_sign_descriptions_With_LR_hand_info_GEMINI25pro.csv'\n","\n","# Ensure CSV has headers if it doesn't exist\n","if not os.path.exists(output_csv):\n","    with open(output_csv, 'w', newline='', encoding='utf-8') as f:\n","        writer = csv.writer(f)\n","        writer.writerow([\"folder_name\", \"file_name\", \"description\"])\n"],"metadata":{"id":"gGDZbML7CrZ_","executionInfo":{"status":"ok","timestamp":1753719660220,"user_tz":-360,"elapsed":59,"user":{"displayName":"Tariq Zaman","userId":"06097184597384541396"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def generate_description(video_path, prompt):\n","    \"\"\"\n","    Uploads video to Gemini, waits for processing, and generates a description.\n","    \"\"\"\n","    model = genai.GenerativeModel('gemini-2.5-pro')\n","\n","    print(f\"\\nUploading: {video_path}\")\n","    video_file = genai.upload_file(path=video_path)\n","    print(f\"Completed upload: {video_file.uri}\")\n","\n","    # Wait until processing is complete\n","    while video_file.state.name == \"PROCESSING\":\n","        print(\"Waiting for video to be processed...\")\n","        time.sleep(10)\n","        video_file = genai.get_file(video_file.name)\n","\n","    if video_file.state.name == \"FAILED\":\n","        raise ValueError(f\"Video processing failed for {video_path}\")\n","\n","    # Generate description\n","    response = model.generate_content([prompt, video_file])\n","    return response.text\n","\n","# The prompt for Gemini\n","prompt = \"\"\"\n","You are an expert sign language motion analyst.\n","You will be given a video of a single hand sign gesture.\n","Your task is to generate a precise, sequential, and movement-focused description of the gesture.\n","\n","Guidelines:\n","1. Break the description into ordered steps (Step 1, Step 2, etc.) capturing the full motion sequence.\n","2. Always specify which hand is involved (right hand, left hand, or both) and describe their actions separately if needed, similarly mention the fingers if there is a very clear distinction among them.\n","3. Focus on:\n","   - Hand positions relative to the body (chest, head, side, etc.).\n","   - Handshape changes (fist, fingers spread, pointing, etc.).\n","   - Motion direction (up, down, circular, inward, outward).\n","   - Wrist rotations or pauses.\n","4. Capture the full flow of the gesture so the sequence can be understood clearly.\n","5. Do NOT provide the sign's meaning or label. Only describe the physical movements.\n","6. Use clear, natural language. Avoid technical or linguistic jargon.\n","7. Output only the step-by-step description, no additional text.\n","\"\"\""],"metadata":{"id":"Z6xXbKthC6w4","executionInfo":{"status":"ok","timestamp":1753719660288,"user_tz":-360,"elapsed":31,"user":{"displayName":"Tariq Zaman","userId":"06097184597384541396"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Gather all folders with a valid video\n","folders = []\n","missing_folders = []  # To track folders without U4/U8 videos\n","\n","for folder_name in os.listdir(base_directory):\n","    folder_path = os.path.join(base_directory, folder_name)\n","    if not os.path.isdir(folder_path):\n","        continue\n","\n","    # Pick U4 or U8 video\n","    video_file = None\n","    for fname in os.listdir(folder_path):\n","        if fname.startswith(\"U4\") and fname.lower().endswith(('.mp4', '.mov', '.avi')):\n","            video_file = fname\n","            break\n","    if video_file is None:\n","        for fname in os.listdir(folder_path):\n","            if fname.startswith(\"U8\") and fname.lower().endswith(('.mp4', '.mov', '.avi')):\n","                video_file = fname\n","                break\n","\n","    if video_file:\n","        folders.append((folder_name, video_file))\n","    else:\n","        missing_folders.append(folder_name)\n","\n","total = len(folders)\n","print(f\"Found {total} videos to process.\")\n","\n","# Report missing folders\n","if missing_folders:\n","    print(\"\\nFolders without U4 or U8 videos:\")\n","    for missing in missing_folders:\n","        print(f\" - {missing}\")\n","else:\n","    print(\"\\nAll folders have at least one U4 or U8 video.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tw5tWYvZDBuQ","executionInfo":{"status":"ok","timestamp":1753719660336,"user_tz":-360,"elapsed":40,"user":{"displayName":"Tariq Zaman","userId":"06097184597384541396"}},"outputId":"c2feb934-a810-4a49-9555-02df9e814844"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 60 videos to process.\n","\n","All folders have at least one U4 or U8 video.\n"]}]},{"cell_type":"code","source":["# Process with progress bar\n","for idx, (folder_name, video_file) in enumerate(folders, 1):\n","    video_path = os.path.join(base_directory, folder_name, video_file)\n","\n","    # Update progress bar\n","    clear_output(wait=True)\n","    progress = int((idx / total) * 30)  # 30-character bar\n","    bar = \"[\" + \"#\" * progress + \"-\" * (30 - progress) + \"]\"\n","    print(f\"Processing {idx}/{total} {bar} {int((idx/total)*100)}%\")\n","\n","    try:\n","        description = generate_description(video_path, prompt)\n","    except Exception as e:\n","        print(f\"Error processing {video_path}: {e}\")\n","        continue\n","\n","    # Print the description for review\n","    print(f\"\\nFolder: {folder_name}\\nVideo: {video_file}\\nDescription:\\n{description}\\n\")\n","\n","    # Save result to CSV\n","    with open(output_csv, 'a', newline='', encoding='utf-8') as f:\n","        writer = csv.writer(f)\n","        writer.writerow([folder_name, video_file, description])\n","\n","    # Short delay (avoid hitting API rate limits)\n","    time.sleep(5)\n","\n","print(f\"\\nAll done! Descriptions saved to: {output_csv}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":176},"id":"R63CDoDbJv9J","executionInfo":{"status":"ok","timestamp":1753720428124,"user_tz":-360,"elapsed":767783,"user":{"displayName":"Tariq Zaman","userId":"06097184597384541396"}},"outputId":"0dfc2c39-166a-4639-a8ae-0c01185afa0a"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing 60/60 [##############################] 100%\n","\n","Uploading: /content/drive/MyDrive/research/BDSLW60GPT/Dataset/u4u8r/debor/U4W11F_trial_3_R.mp4\n","Completed upload: https://generativelanguage.googleapis.com/v1beta/files/r03a7xn79gmt\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tornado.access:429 POST /v1beta/models/gemini-2.5-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 684.34ms\n"]},{"output_type":"stream","name":"stdout","text":["Error processing /content/drive/MyDrive/research/BDSLW60GPT/Dataset/u4u8r/debor/U4W11F_trial_3_R.mp4: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-pro:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n","\n","All done! Descriptions saved to: /content/drive/MyDrive/research/BDSLW60GPT/Output/VideoToUnstructuredText_sign_descriptions_With_LR_hand_info_GEMINI25pro.csv\n"]}]}]}
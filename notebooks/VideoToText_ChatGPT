{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Description\n","We pass each video to LLMs to generate textual descritions, no descrition format is given"],"metadata":{"id":"WPayWLrI2iTq"}},{"cell_type":"code","source":["video_file_path = '/content/drive/MyDrive/research/BDSLW60GPT/Dataset/u4u8r/aam/U4W37F_trial_3_R.mp4'\n"],"metadata":{"id":"IHgXOmu_gOQH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Single File Test"],"metadata":{"id":"qttu5a8dChVK"}},{"cell_type":"code","source":["!pip install --quiet opencv-python\n","!pip install --upgrade openai"],"metadata":{"id":"bJ4gtZeHnhwD"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pMh_3zYk45z5","executionInfo":{"status":"ok","timestamp":1753716022128,"user_tz":-360,"elapsed":4524,"user":{"displayName":"researchtempmailiut","userId":"17878600714424444378"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c77e4853-b87b-4fb0-c66f-8236a6826e79"},"source":["import cv2\n","import base64\n","import time\n","from openai import OpenAI\n","import os\n","from IPython.display import display, Image\n","from openai import OpenAI\n","from google.colab import userdata  # For Colab Secrets\n","\n","# Configure API key\n","try:\n","    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n","    client = OpenAI(api_key=OPENAI_API_KEY)\n","except userdata.SecretNotFoundError:\n","    print(\"Secret not found. Please add your OPENAI_API_KEY to Colab Secrets Manager.\")\n","    # Or set manually:\n","    # client = OpenAI(api_key=\"YOUR_OPENAI_API_KEY\")\n","\n","# 2. Path to your sign language video\n","video_file_path = '/content/drive/MyDrive/research/BDSLW60GPT/Dataset/u4u8r/aam/U4W37F_trial_3_R.mp4'\n","\n","# 3. Extract frames and convert to base64\n","video = cv2.VideoCapture(video_file_path)\n","base64_frames = []\n","\n","while video.isOpened():\n","    success, frame = video.read()\n","    if not success:\n","        break\n","    # Encode frame as JPEG\n","    _, buffer = cv2.imencode(\".jpg\", frame)\n","    # Convert to base64 string\n","    base64_frames.append(base64.b64encode(buffer).decode(\"utf-8\"))\n","\n","video.release()\n","print(f\"Total frames extracted: {len(base64_frames)}\")\n","\n","# Optional: Display a few frames to verify (uncomment if needed)\n","# for i, img_b64 in enumerate(base64_frames[::len(base64_frames)//5]):\n","#     display(Image(data=base64.b64decode(img_b64)))\n","\n","# 4. Prepare the prompt for sign language gesture description\n","prompt = \"\"\"\n","You are an expert sign language motion analyst.\n","You will be given a video of a single hand sign gesture.\n","Your task is to generate a precise, natural language, movement-focused description of the gesture.\n","\n","Guidelines:\n","1. Break the description into ordered steps (Step 1, Step 2, etc.) that together capture the full gesture.\n","2. Describe what each hand is doing (right hand, left hand, or both), and specify finger involvement when clearly distinguishable.\n","3. Integrate the following movement parameters naturally into your step-by-step narrative:\n","   - Handshape (e.g., open, fist, hooked, pointing)\n","   - Type and direction of movement (e.g., straight upward, circular outward, twisting inward)\n","   - Palm orientation (e.g., facing forward, downward)\n","   - Relative body location (e.g., near the forehead, at chest level, beside the shoulder)\n","   - Spatial interaction between hands (e.g., touching, parallel, crossing)\n","   - Temporal dynamics (e.g., smooth transition, repeated motion, paused hold)\n","   - Non-manual cues (e.g., neutral face, raised eyebrows, head tilt)\n","   - Lexical context (starting position, transition phase, holding position, ending)\n","\n","4. Avoid listing these categories explicitly. Instead, embed them fluidly into your language so the description reads like a natural narrative of observed motion.\n","5. Do NOT include the meaning of the sign. Focus only on physical and expressive detail.\n","6. Keep the tone clear, concise, and easy to follow. Do not use technical or linguistic jargon.\n","7. Output only the step-by-step description. Do not include any introductory or closing remarks.\n","\"\"\"\n","\n","\n","# 5. Select frames to send (e.g., every 20th frame to limit token size)\n","sampled_frames = base64_frames[0::20]\n","\n","# 6. Build the message content with input_text + input_image frames\n","message_content = [\n","    {\"type\": \"input_text\", \"text\": prompt},\n","    *[\n","        {\"type\": \"input_image\", \"image_url\": f\"data:image/jpeg;base64,{frame_b64}\"}\n","        for frame_b64 in sampled_frames\n","    ]\n","]\n","\n","# 7. Send request to GPT-4.1-mini with vision support\n","response = client.responses.create(\n","    model=\"gpt-4.1\",\n","    input=[\n","        {\n","            \"role\": \"user\",\n","            \"content\": message_content\n","        }\n","    ]\n",")\n","\n","# 8. Print the generated description\n","print(response.output_text)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total frames extracted: 13\n","Step 1: The hand starts near the face, with fingers loosely curled and the palm facing inward.  \n","Step 2: The hand moves slightly forward and upward away from the face while maintaining the loose curl.  \n","Step 3: The fingers straighten slightly as the hand continues moving forward, with a subtle wrist rotation so the palm gradually faces more outward.  \n","Step 4: The hand settles in front of the chest area with fingers still partially curled and palm facing outward.\n"]}]},{"cell_type":"markdown","source":["## Prompts"],"metadata":{"id":"Td5sNqnAxD6R"}},{"cell_type":"markdown","source":["### Basic, no structure, no hand mentioned\n","prompt = \"\"\"\n","You are an expert sign language motion analyst.\n","You will be given a video of a single hand sign gesture.\n","Your job is to produce a clear, accurate, and sequential description of the gesture, focusing on movement and meaning.\n","\n","Guidelines:\n","1. Describe the gesture in steps, following the order of motion (e.g., \"Step 1: Hand rises near the chest. Step 2: Fingers spread outward while rotating clockwise\").\n","2. Focus on the overall movement, direction, hand shape changes, and important transitions.\n","3. Avoid guessing the meaning or label. Only describe what is physically happening.\n","4. Be specific but concise. Use natural language rather than technical jargon.\n","5. Capture the \"flow\" of the gesture so another system can infer the meaning later.\n","6. Output only the description (no introductions or conclusions).\n","\"\"\""],"metadata":{"id":"YM1dG5n9xFlc"}},{"cell_type":"markdown","source":["### Basic, no structure, hand mentioned\n","prompt = \"\"\"\n","You are an expert sign language motion analyst.\n","You will be given a video of a single hand sign gesture.\n","Your task is to generate a precise, sequential, and movement-focused description of the gesture.\n","\n","Guidelines:\n","1. Break the description into ordered steps (Step 1, Step 2, etc.) capturing the full motion sequence.\n","2. Always specify which hand is involved (right hand, left hand, or both) and describe their actions separately if needed, similarly mention the fingers if there is a very clear distinction among them.\n","3. Focus on:\n","   - Hand positions relative to the body (chest, head, side, etc.).\n","   - Handshape changes (fist, fingers spread, pointing, etc.).\n","   - Motion direction (up, down, circular, inward, outward).\n","   - Wrist rotations or pauses.\n","4. Capture the full flow of the gesture so the sequence can be understood clearly.\n","5. Do NOT provide the sign's meaning or label. Only describe the physical movements.\n","6. Use clear, natural language. Avoid technical or linguistic jargon.\n","7. Output only the step-by-step description, no additional text.\n","\"\"\""],"metadata":{"id":"8K4W_5YkxMGl"}},{"cell_type":"markdown","source":["# Structured Discrete Values\n","prompt = \"\"\"\n","You are an expert sign language motion analyst.\n","You will be given a video of a single hand sign gesture.\n","Your task is to break the gesture into steps and extract only structured, discrete feature values for each step.\n","No natural-language sentences — only standardized attributes.\n","\n","Guidelines:\n","1. Divide the gesture into ordered steps (Step 1, Step 2, etc.) capturing every motion change.\n","2. For each step, generate a JSON-like feature set with the following keys:\n","   - Handshape: (open, fist, hooked, pointing, spread, bent, extended, etc.)\n","   - MovementType: (static, circular, straight, twisting, grabbing, rotating, spreading, pulling, squeezing)\n","   - Location: (relative to body — head, forehead, ear, eye, nose, mouth, face, neck, shoulder, chest, waist, side)\n","   - PalmOrientation: (forward, inward, outward, upward, downward)\n","   - SpatialInteraction: (touching, crossing, parallel, apart, overlapping)\n","   - MovementDirection: (inward, outward, left, right, upward, downward, forward, backward, straight)\n","   - TemporalDynamics: (smooth, abrupt, repeated, paused, continuous)\n","   - NonManualCues: (neutral, nodding, raised eyebrows, head tilt, facial tension)\n","   - LexicalContext: (starting position, motion, transition, holding, ending)\n","\n","3. Always specify which hand is involved (right hand, left hand, or both) within the feature values when relevant (e.g., `\"Handshape\": \"right-hand spread, left-hand fist\"`).\n","\n","4. Do NOT provide natural-language sentences or the sign meaning.\n","\n","5. Output format: For each step, write only:\n","```\n","\n","Step N:\n","{\n","\"Handshape\": \"...\",\n","\"MovementType\": \"...\",\n","\"Location\": \"...\",\n","\"PalmOrientation\": \"...\",\n","\"SpatialInteraction\": \"...\",\n","\"MovementDirection\": \"...\",\n","\"TemporalDynamics\": \"...\",\n","\"NonManualCues\": \"...\",\n","\"LexicalContext\": \"...\"\n","}\n","\n","```\n","6. Output only the ordered steps for the gesture. No introductions or summaries.\"\"\"\n"],"metadata":{"id":"wIjbj5puycSl"}},{"cell_type":"markdown","source":["### Parameter Injection Natural Language\n","prompt = \"\"\"\n","You are an expert sign language motion analyst.\n","You will be given a video of a single hand sign gesture.\n","Your task is to generate a precise, natural language, movement-focused description of the gesture.\n","\n","Guidelines:\n","1. Break the description into ordered steps (Step 1, Step 2, etc.) that together capture the full gesture.\n","2. Describe what each hand is doing (right hand, left hand, or both), and specify finger involvement when clearly distinguishable.\n","3. Integrate the following movement parameters naturally into your step-by-step narrative:\n","   - Handshape (e.g., open, fist, hooked, pointing)\n","   - Type and direction of movement (e.g., straight upward, circular outward, twisting inward)\n","   - Palm orientation (e.g., facing forward, downward)\n","   - Relative body location (e.g., near the forehead, at chest level, beside the shoulder)\n","   - Spatial interaction between hands (e.g., touching, parallel, crossing)\n","   - Temporal dynamics (e.g., smooth transition, repeated motion, paused hold)\n","   - Non-manual cues (e.g., neutral face, raised eyebrows, head tilt)\n","   - Lexical context (starting position, transition phase, holding position, ending)\n","\n","4. Avoid listing these categories explicitly. Instead, embed them fluidly into your language so the description reads like a natural narrative of observed motion.\n","5. Do NOT include the meaning of the sign. Focus only on physical and expressive detail.\n","6. Keep the tone clear, concise, and easy to follow. Do not use technical or linguistic jargon.\n","7. Output only the step-by-step description. Do not include any introductory or closing remarks.\n","\"\"\""],"metadata":{"id":"GFtbVoCC8mdi"}},{"cell_type":"markdown","source":["### Batch Test"],"metadata":{"id":"YFaLHMDHCj3C"}},{"cell_type":"code","source":["import os\n","import csv\n","import cv2\n","import base64\n","import time\n","from openai import OpenAI\n","from IPython.display import clear_output\n","from google.colab import drive, userdata\n","\n","# === Step 1: Mount Google Drive ===\n","drive.mount('/content/drive')\n","\n","# === Step 2: Configure OpenAI API Key ===\n","try:\n","    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n","    client = OpenAI(api_key=OPENAI_API_KEY)\n","except userdata.SecretNotFoundError:\n","    print(\"Secret not found. Please add your OPENAI_API_KEY to Colab Secrets Manager.\")\n","    # Or set manually:\n","    # client = OpenAI(api_key=\"YOUR_OPENAI_API_KEY\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WHWbz4UdCk0m","executionInfo":{"status":"ok","timestamp":1753776026028,"user_tz":-360,"elapsed":7135,"user":{"displayName":"researchtempmailiut","userId":"17878600714424444378"}},"outputId":"8db9ca61-161b-428d-ab84-f5f14ef6390c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# === Step 3: Paths ===\n","base_directory = '/content/drive/MyDrive/research/BDSLW60GPT/Dataset/u4u8r'\n","output_csv = '/content/drive/MyDrive/research/BDSLW60GPT/Output/VideoToImageToStructuredText_sign_descriptions_parameter_injection_ChatGPT_4_1mini.csv'\n","\n","# === Step 4: Prompt ===\n","prompt = \"\"\"\n","You are an expert sign language motion analyst.\n","You will be given a video of a single hand sign gesture.\n","Your task is to generate a precise, natural language, movement-focused description of the gesture.\n","\n","Guidelines:\n","1. Break the description into ordered steps (Step 1, Step 2, etc.) that together capture the full gesture.\n","2. Describe what each hand is doing (right hand, left hand, or both), and specify finger involvement when clearly distinguishable.\n","3. Integrate the following movement parameters naturally into your step-by-step narrative:\n","   - Handshape (e.g., open, fist, hooked, pointing)\n","   - Type and direction of movement (e.g., straight upward, circular outward, twisting inward)\n","   - Palm orientation (e.g., facing forward, downward)\n","   - Relative body location (e.g., near the forehead, at chest level, beside the shoulder)\n","   - Spatial interaction between hands (e.g., touching, parallel, crossing)\n","   - Temporal dynamics (e.g., smooth transition, repeated motion, paused hold)\n","   - Non-manual cues (e.g., neutral face, raised eyebrows, head tilt)\n","   - Lexical context (starting position, transition phase, holding position, ending)\n","\n","4. Avoid listing these categories explicitly. Instead, embed them fluidly into your language so the description reads like a natural narrative of observed motion.\n","5. Do NOT include the meaning of the sign. Focus only on physical and expressive detail.\n","6. Keep the tone clear, concise, and easy to follow. Do not use technical or linguistic jargon.\n","7. Output only the step-by-step description. Do not include any introductory or closing remarks.\n","\"\"\"\n","\n","# === Step 5: CSV Header ===\n","if not os.path.exists(output_csv):\n","    with open(output_csv, 'w', newline='', encoding='utf-8') as f:\n","        writer = csv.writer(f)\n","        writer.writerow([\"folder_name\", \"file_name\", \"description\"])"],"metadata":{"id":"gGDZbML7CrZ_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# === Step 6: Frame Extraction Helper ===\n","def extract_sampled_frames(video_path, every_n=20):\n","    video = cv2.VideoCapture(video_path)\n","    base64_frames = []\n","    frame_count = 0\n","\n","    while video.isOpened():\n","        success, frame = video.read()\n","        if not success:\n","            break\n","        if frame_count % every_n == 0:\n","            _, buffer = cv2.imencode(\".jpg\", frame)\n","            base64_frames.append(base64.b64encode(buffer).decode(\"utf-8\"))\n","        frame_count += 1\n","\n","    video.release()\n","    return base64_frames\n","\n","# === Step 7: Generate Description from Sampled Frames ===\n","def generate_description(video_path):\n","    frames_b64 = extract_sampled_frames(video_path, every_n=20)\n","\n","    if len(frames_b64) == 0:\n","        return \"ERROR: No frames extracted.\"\n","\n","    message_content = [\n","        {\"type\": \"input_text\", \"text\": prompt},\n","        *[\n","            {\"type\": \"input_image\", \"image_url\": f\"data:image/jpeg;base64,{b64}\"}\n","            for b64 in frames_b64\n","        ]\n","    ]\n","\n","    response = client.responses.create(\n","        model=\"gpt-4.1-mini\",\n","        input=[{\"role\": \"user\", \"content\": message_content}]\n","    )\n","\n","    return response.output_text"],"metadata":{"id":"Z6xXbKthC6w4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Find all folders and video files starting with U4 or U8\n","folders = []\n","missing_folders = []\n","for folder_name in os.listdir(base_directory):\n","    folder_path = os.path.join(base_directory, folder_name)\n","    if not os.path.isdir(folder_path):\n","        continue\n","    video_file = None\n","    for fname in os.listdir(folder_path):\n","        if fname.startswith(\"U4\") and fname.lower().endswith(('.mp4', '.mov', '.avi')):\n","            video_file = fname\n","            break\n","    if video_file is None:\n","        for fname in os.listdir(folder_path):\n","            if fname.startswith(\"U8\") and fname.lower().endswith(('.mp4', '.mov', '.avi')):\n","                video_file = fname\n","                break\n","    if video_file:\n","        folders.append((folder_name, video_file))\n","    else:\n","        missing_folders.append(folder_name)\n","\n","total = len(folders)\n","print(f\"Found {total} videos to process.\")\n","\n","if missing_folders:\n","    print(\"Folders missing U4/U8 videos:\")\n","    for m in missing_folders:\n","        print(f\" - {m}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tw5tWYvZDBuQ","executionInfo":{"status":"ok","timestamp":1753776026118,"user_tz":-360,"elapsed":25,"user":{"displayName":"researchtempmailiut","userId":"17878600714424444378"}},"outputId":"9a6b2d01-1ce3-4bf8-da95-15649b8b6c04"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 60 videos to process.\n"]}]},{"cell_type":"code","source":["# === Step 8: Scan Folders and Collect Videos ===\n","folders = []\n","missing_folders = []\n","\n","for folder_name in os.listdir(base_directory):\n","    folder_path = os.path.join(base_directory, folder_name)\n","    if not os.path.isdir(folder_path):\n","        continue\n","\n","    video_file = None\n","    for fname in os.listdir(folder_path):\n","        if fname.startswith(\"U4\") and fname.lower().endswith(('.mp4', '.mov', '.avi')):\n","            video_file = fname\n","            break\n","    if video_file is None:\n","        for fname in os.listdir(folder_path):\n","            if fname.startswith(\"U8\") and fname.lower().endswith(('.mp4', '.mov', '.avi')):\n","                video_file = fname\n","                break\n","\n","    if video_file:\n","        folders.append((folder_name, video_file))\n","    else:\n","        missing_folders.append(folder_name)\n","\n","print(f\"✅ Found {len(folders)} videos to process.\")\n","if missing_folders:\n","    print(\"\\n⚠️ Folders without U4/U8 videos:\")\n","    for missing in missing_folders:\n","        print(f\" - {missing}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R63CDoDbJv9J","executionInfo":{"status":"ok","timestamp":1753776026165,"user_tz":-360,"elapsed":47,"user":{"displayName":"researchtempmailiut","userId":"17878600714424444378"}},"outputId":"14b20f24-30e6-441f-ed8a-283a3989cd7c","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Found 60 videos to process.\n"]}]},{"cell_type":"code","source":["# === Step 9: Batch Processing ===\n","for idx, (folder_name, video_file) in enumerate(folders, 1):\n","    video_path = os.path.join(base_directory, folder_name, video_file)\n","\n","    clear_output(wait=True)\n","    progress = int((idx / len(folders)) * 30)\n","    print(f\"Processing {idx}/{len(folders)} [{'#'*progress}{'-'*(30-progress)}] {int((idx/len(folders))*100)}%\")\n","    print(f\"📂 {folder_name} | 🎥 {video_file}\")\n","\n","    try:\n","        description = generate_description(video_path)\n","    except Exception as e:\n","        print(f\"❌ Error processing {video_file}: {e}\")\n","        continue\n","\n","    print(f\"\\n📝 Description:\\n{description}\\n\")\n","\n","    with open(output_csv, 'a', newline='', encoding='utf-8') as f:\n","        writer = csv.writer(f)\n","        writer.writerow([folder_name, video_file, description])\n","\n","    time.sleep(5)  # Delay to avoid rate limits\n","\n","print(f\"\\n✅ All done! Output saved to: {output_csv}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-1RaaNE5p8GF","executionInfo":{"status":"ok","timestamp":1753776543211,"user_tz":-360,"elapsed":517043,"user":{"displayName":"researchtempmailiut","userId":"17878600714424444378"}},"outputId":"ae4aea09-321e-4ada-bc4b-8eea2fd50921"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing 60/60 [##############################] 100%\n","📂 debor | 🎥 U4W11F_trial_3_R.mp4\n","\n","📝 Description:\n","Step 1: The right hand begins with fingers loosely curled into a relaxed fist, positioned near the right side of the head. The palm faces inward toward the head as the hand moves upwards in a smooth, controlled motion.\n","\n","Step 2: The right hand then pauses near the temple, maintaining the same handshape and palm orientation, creating a held position momentarily.\n","\n","Step 3: Following the hold, the right hand extends outward and downward, fingers still loosely curled, moving away from the head to shoulder level.\n","\n","Step 4: The hand then rotates so the palm faces downward, fingers now pointing slightly forward, and remains steady at shoulder height, completing the gesture with a calm, neutral facial expression throughout.\n","\n","\n","✅ All done! Output saved to: /content/drive/MyDrive/research/BDSLW60GPT/Output/VideoToImageToStructuredText_sign_descriptions_parameter_injection_ChatGPT_4_1mini.csv\n"]}]}]}